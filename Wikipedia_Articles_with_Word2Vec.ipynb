{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wikipedia Articles with Word2Vec.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S_igYj4nPal",
        "outputId": "a90ce0c9-bab2-4d81-c904-86827538e826"
      },
      "source": [
        "!pip install wikipedia\n",
        "!pip install gensim"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11696 sha256=08c948663b13399aa6e892b26feeb2d17931076c9bfa71b8b353ead258bb49b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/93/6d/5b2c68b8a64c7a7a04947b4ed6d89fb557dcc6bc27d1d7f3ba\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.1.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJk50oqjo0CW",
        "outputId": "f5127bb5-8d69-4a24-f4e7-d69075d778c2"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"all\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjA_r4PxoQlf"
      },
      "source": [
        "## Importing the Libraries ##\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMKGbt2vocUX"
      },
      "source": [
        "import string\n",
        "import warnings\n",
        "from gensim.models import Word2Vec\n",
        "warnings.filterwarnings(action=\"ignore\", category = UserWarning, module=\"gensim\")\n",
        "\n",
        "import wikipedia\n",
        "from wikipedia import search\n",
        "from wikipedia import page"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAnERl7rogrm",
        "outputId": "696b0abc-d25a-44d8-86f1-fc7bc312931e"
      },
      "source": [
        "## Working with Wikipedia ##\n",
        "titles = search(\"Data Science\")\n",
        "wikipage = page(titles[0])\n",
        "wikipage.content\n",
        "wikipage.categories\n",
        "wikipedia.summary(\"Data Science\", sentences = 1)\n",
        "wikipedia.search(\"Data Science\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Data science',\n",
              " 'Master in Data Science',\n",
              " 'Data analysis',\n",
              " 'Open science data',\n",
              " 'Big data',\n",
              " 'Data',\n",
              " 'Data type',\n",
              " 'Data structure',\n",
              " 'Computer science',\n",
              " 'Committee on Data for Science and Technology']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knRMJmLromBt",
        "outputId": "b44ffe10-c1d5-4625-b6e9-b3886c5f49de"
      },
      "source": [
        "## Apply Natural Language Processing with function ##\n",
        "def preprocessing(text):\n",
        "    result = []\n",
        "    sent = sent_tokenize(text)\n",
        "    for sentence in sent:\n",
        "        words = word_tokenize(sentence)\n",
        "        tokens = [w for w in words if w.lower() not in string.punctuation]\n",
        "        stopw = stopwords.words(\"english\")\n",
        "        tokens = [token for token in tokens if token not in stopw]        \n",
        "        tokens = [word for word in tokens if len(word)>= 3]        \n",
        "        lemma = WordNetLemmatizer()\n",
        "        tokens = [lemma.lemmatize(word) for word in tokens]\n",
        "        result += [tokens]\n",
        "        \n",
        "    return result\n",
        "text_p = preprocessing(wikipage.content)\n",
        "text_p[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Data',\n",
              " 'science',\n",
              " 'interdisciplinary',\n",
              " 'field',\n",
              " 'us',\n",
              " 'scientific',\n",
              " 'method',\n",
              " 'process',\n",
              " 'algorithm',\n",
              " 'system',\n",
              " 'extract',\n",
              " 'knowledge',\n",
              " 'insight',\n",
              " 'structured',\n",
              " 'unstructured',\n",
              " 'data',\n",
              " 'apply',\n",
              " 'knowledge',\n",
              " 'actionable',\n",
              " 'insight',\n",
              " 'data',\n",
              " 'across',\n",
              " 'broad',\n",
              " 'range',\n",
              " 'application',\n",
              " 'domain']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HyEQdf9pgCJ"
      },
      "source": [
        "## Create the Model ##    \n",
        "min_count = 2\n",
        "size = 50\n",
        "window = 4\n",
        "\n",
        "wikimodel = Word2Vec(text_p, min_count = min_count, size = size, window = window)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE4hZKXyqIot",
        "outputId": "69aaf4ad-75a2-4c1b-9a23-c2bcd4e87f6c"
      },
      "source": [
        "## See the Result ##\n",
        "vocab = list(wikimodel.wv.vocab.keys())\n",
        "vocab[ :10]    \n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Data',\n",
              " 'science',\n",
              " 'interdisciplinary',\n",
              " 'field',\n",
              " 'us',\n",
              " 'method',\n",
              " 'process',\n",
              " 'algorithm',\n",
              " 'system',\n",
              " 'knowledge']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0aeM-TgqMFt",
        "outputId": "38e24594-bf26-4368-b1f0-1e0a0f96539c"
      },
      "source": [
        "wikimodel.wv.most_similar(positive = [\"method\", \"process\"], topn = 3)\n",
        "print(wikimodel.wv.similarity(\"data\", \"interdisciplinary\"))\n",
        "print(wikimodel.wv.similarity(\"data\", \"science\"))\n",
        "print(wikimodel.wv.similarity(\"data\", \"system\"))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.010974535\n",
            "-0.15512955\n",
            "0.027328903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHxNxtAArG4h"
      },
      "source": [
        "Another Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mrrPwTNqWyy",
        "outputId": "fb107f33-27bf-4c39-c291-91cfd81e7d73"
      },
      "source": [
        "## Working with Wikipedia ##\n",
        "titles = search(\"Algorithm\")\n",
        "wikipage = page(titles[0])\n",
        "wikipage.content\n",
        "wikipage.categories\n",
        "wikipedia.summary(\"Algorithm\", sentences = 1)\n",
        "wikipedia.search(\"Algorithm\")\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Algorithm',\n",
              " 'The Algorithm',\n",
              " 'Sorting algorithm',\n",
              " \"Dijkstra's algorithm\",\n",
              " 'A* search algorithm',\n",
              " 'Euclidean algorithm',\n",
              " 'Quantum algorithm',\n",
              " \"Prim's algorithm\",\n",
              " 'Algorithmic',\n",
              " 'Floyd–Warshall algorithm']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YgUXcrYrPCO",
        "outputId": "174ee495-a307-436f-f280-b28f17ffadb6"
      },
      "source": [
        "## Apply Natural Language Processing with function ##\n",
        "def preprocessing(text):\n",
        "    result = []\n",
        "    sent = sent_tokenize(text)\n",
        "    for sentence in sent:\n",
        "        words = word_tokenize(sentence)\n",
        "        tokens = [w for w in words if w.lower() not in string.punctuation]\n",
        "        stopw = stopwords.words(\"english\")\n",
        "        tokens = [token for token in tokens if token not in stopw]        \n",
        "        tokens = [word for word in tokens if len(word)>= 3]        \n",
        "        lemma = WordNetLemmatizer()\n",
        "        tokens = [lemma.lemmatize(word) for word in tokens]\n",
        "        result += [tokens]\n",
        "        \n",
        "    return result\n",
        "text_p = preprocessing(wikipage.content)\n",
        "text_p[0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mathematics',\n",
              " 'computer',\n",
              " 'science',\n",
              " 'algorithm',\n",
              " 'listen',\n",
              " 'finite',\n",
              " 'sequence',\n",
              " 'well-defined',\n",
              " 'computer-implementable',\n",
              " 'instruction',\n",
              " 'typically',\n",
              " 'solve',\n",
              " 'class',\n",
              " 'specific',\n",
              " 'problem',\n",
              " 'perform',\n",
              " 'computation']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDoUn5EArTDJ"
      },
      "source": [
        "## Create the Model ##    \n",
        "min_count = 2\n",
        "size = 50\n",
        "window = 4\n",
        "\n",
        "wikimodel = Word2Vec(text_p, min_count = min_count, size = size, window = window)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaeVEOnXrW31",
        "outputId": "34461f19-f751-4201-9a6d-ba78b204dcb1"
      },
      "source": [
        "## See the Result ##\n",
        "vocab = list(wikimodel.wv.vocab.keys())\n",
        "vocab   "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mathematics',\n",
              " 'computer',\n",
              " 'science',\n",
              " 'algorithm',\n",
              " 'finite',\n",
              " 'sequence',\n",
              " 'well-defined',\n",
              " 'instruction',\n",
              " 'solve',\n",
              " 'class',\n",
              " 'specific',\n",
              " 'problem',\n",
              " 'perform',\n",
              " 'computation',\n",
              " 'Algorithms',\n",
              " 'always',\n",
              " 'used',\n",
              " 'specification',\n",
              " 'performing',\n",
              " 'calculation',\n",
              " 'data',\n",
              " 'processing',\n",
              " 'automated',\n",
              " 'reasoning',\n",
              " 'task',\n",
              " 'heuristic',\n",
              " 'technique',\n",
              " 'solving',\n",
              " 'us',\n",
              " 'practical',\n",
              " 'method',\n",
              " 'various',\n",
              " 'estimate',\n",
              " 'order',\n",
              " 'produce',\n",
              " 'solution',\n",
              " 'may',\n",
              " 'optimal',\n",
              " 'given',\n",
              " 'circumstance',\n",
              " 'effective',\n",
              " 'expressed',\n",
              " 'within',\n",
              " 'amount',\n",
              " 'space',\n",
              " 'time',\n",
              " 'formal',\n",
              " 'language',\n",
              " 'calculating',\n",
              " 'function',\n",
              " 'initial',\n",
              " 'state',\n",
              " 'input',\n",
              " 'perhaps',\n",
              " 'empty',\n",
              " 'describe',\n",
              " 'executed',\n",
              " 'proceeds',\n",
              " 'number',\n",
              " 'successive',\n",
              " 'eventually',\n",
              " 'producing',\n",
              " 'output',\n",
              " 'The',\n",
              " 'transition',\n",
              " 'one',\n",
              " 'next',\n",
              " 'necessarily',\n",
              " 'deterministic',\n",
              " 'known',\n",
              " 'randomized',\n",
              " 'random',\n",
              " 'concept',\n",
              " 'Arithmetic',\n",
              " 'division',\n",
              " 'ancient',\n",
              " 'Babylonian',\n",
              " 'mathematician',\n",
              " '2500',\n",
              " 'Egyptian',\n",
              " '1550',\n",
              " 'Greek',\n",
              " 'later',\n",
              " 'Eratosthenes',\n",
              " 'finding',\n",
              " 'prime',\n",
              " 'Euclidean',\n",
              " 'greatest',\n",
              " 'common',\n",
              " 'divisor',\n",
              " 'two',\n",
              " 'Arabic',\n",
              " '9th',\n",
              " 'century',\n",
              " 'cryptographic',\n",
              " 'based',\n",
              " 'frequency',\n",
              " 'word',\n",
              " 'derived',\n",
              " 'name',\n",
              " '9th-century',\n",
              " 'ibn',\n",
              " 'Mūsā',\n",
              " 'al-Khwārizmī',\n",
              " 'whose',\n",
              " 'nisba',\n",
              " 'Khwarazm',\n",
              " 'partial',\n",
              " 'formalization',\n",
              " 'modern',\n",
              " 'attempt',\n",
              " 'Entscheidungsproblem',\n",
              " 'decision',\n",
              " 'Hilbert',\n",
              " '1928',\n",
              " 'framed',\n",
              " 'define',\n",
              " 'calculability',\n",
              " 'Those',\n",
              " 'recursive',\n",
              " '1934',\n",
              " 'Alonzo',\n",
              " 'Church',\n",
              " 'calculus',\n",
              " '1936',\n",
              " 'Emil',\n",
              " 'Post',\n",
              " 'Alan',\n",
              " 'Turing',\n",
              " 'machine',\n",
              " '1936–37',\n",
              " '1939',\n",
              " \"'algorithm\",\n",
              " 'root',\n",
              " 'Persian',\n",
              " 'Muhammad',\n",
              " 'al-Khwarizmi',\n",
              " 'algorismus',\n",
              " 'Baghdad',\n",
              " 'mean',\n",
              " 'part',\n",
              " 'wrote',\n",
              " 'numeral',\n",
              " 'system',\n",
              " 'Latin',\n",
              " 'start',\n",
              " 'Algorizmi',\n",
              " 'Al-Khwarizmi',\n",
              " 'read',\n",
              " 'Europe',\n",
              " 'late',\n",
              " 'Middle',\n",
              " 'Ages',\n",
              " 'primarily',\n",
              " 'another',\n",
              " 'book',\n",
              " 'English',\n",
              " 'meant',\n",
              " 'influence',\n",
              " 'corresponding',\n",
              " 'term',\n",
              " 'first',\n",
              " 'sense',\n",
              " '19th',\n",
              " \"n't\",\n",
              " 'meaning',\n",
              " 'use',\n",
              " 'composed',\n",
              " 'Indorum',\n",
              " 'art',\n",
              " 'present',\n",
              " 'Indian',\n",
              " 'five',\n",
              " 'long',\n",
              " 'new',\n",
              " 'definition',\n",
              " 'informal',\n",
              " 'could',\n",
              " 'set',\n",
              " 'rule',\n",
              " 'precisely',\n",
              " 'defines',\n",
              " 'operation',\n",
              " 'would',\n",
              " 'include',\n",
              " 'program',\n",
              " 'including',\n",
              " 'example',\n",
              " 'procedure',\n",
              " 'general',\n",
              " 'stop',\n",
              " 'though',\n",
              " 'infinite',\n",
              " 'loop',\n",
              " 'sometimes',\n",
              " 'prove',\n",
              " 'desirable',\n",
              " 'maximum',\n",
              " 'integer',\n",
              " 'others',\n",
              " 'described',\n",
              " 'flowchart',\n",
              " 'Boolos',\n",
              " 'Jeffrey',\n",
              " 'offer',\n",
              " 'following',\n",
              " 'human',\n",
              " 'write',\n",
              " 'fast',\n",
              " 'enough',\n",
              " 'small',\n",
              " 'smaller',\n",
              " 'without',\n",
              " 'trying',\n",
              " 'list',\n",
              " 'member',\n",
              " 'enumerably',\n",
              " 'writing',\n",
              " 'notation',\n",
              " 'But',\n",
              " 'something',\n",
              " 'useful',\n",
              " 'case',\n",
              " 'certain',\n",
              " 'They',\n",
              " 'give',\n",
              " 'arbitrary',\n",
              " 'Such',\n",
              " 'explicitly',\n",
              " 'form',\n",
              " 'computing',\n",
              " 'capable',\n",
              " 'elementary',\n",
              " 'symbol',\n",
              " 'element',\n",
              " 'put',\n",
              " 'Thus',\n",
              " 'implies',\n",
              " 'process',\n",
              " 'creates',\n",
              " 'theory',\n",
              " 'large',\n",
              " 'For',\n",
              " 'algebraic',\n",
              " 'equation',\n",
              " 'i.e.',\n",
              " 'variable',\n",
              " 'author',\n",
              " 'notion',\n",
              " 'indicate',\n",
              " 'much',\n",
              " 'addition',\n",
              " 'understood',\n",
              " 'efficient',\n",
              " 'good',\n",
              " 'specifies',\n",
              " 'move',\n",
              " 'equipped',\n",
              " 'information',\n",
              " 'capability',\n",
              " 'find',\n",
              " 'effectively',\n",
              " 'specified',\n",
              " 'place',\n",
              " 'also',\n",
              " 'come',\n",
              " 'starting',\n",
              " 'axiom',\n",
              " 'logic',\n",
              " 'requires',\n",
              " 'complete',\n",
              " 'measured',\n",
              " 'From',\n",
              " 'work',\n",
              " 'concrete',\n",
              " 'abstract',\n",
              " 'usage',\n",
              " 'essential',\n",
              " 'way',\n",
              " 'Many',\n",
              " 'contain',\n",
              " 'detail',\n",
              " 'card',\n",
              " 'considered',\n",
              " 'simulated',\n",
              " 'Turing-complete',\n",
              " 'thesis',\n",
              " 'Minsky',\n",
              " 'Savage',\n",
              " '1987',\n",
              " 'Gurevich',\n",
              " '2000',\n",
              " 'naturally',\n",
              " 'called',\n",
              " 'fact',\n",
              " 'realized',\n",
              " 'simple',\n",
              " 'seem',\n",
              " 'argument',\n",
              " 'favor',\n",
              " 'hard',\n",
              " 'every',\n",
              " 'according',\n",
              " 'computational',\n",
              " 'defined',\n",
              " 'generally',\n",
              " 'require',\n",
              " 'terminates',\n",
              " 'This',\n",
              " 'requirement',\n",
              " 'whether',\n",
              " 'computability',\n",
              " 'associated',\n",
              " 'source',\n",
              " 'written',\n",
              " 'device',\n",
              " 'stored',\n",
              " 'structure',\n",
              " 'must',\n",
              " 'possible',\n",
              " 'conditional',\n",
              " 'step',\n",
              " 'criterion',\n",
              " 'clear',\n",
              " 'computable',\n",
              " 'precise',\n",
              " 'usually',\n",
              " 'assumed',\n",
              " 'top',\n",
              " '—an',\n",
              " 'idea',\n",
              " 'flow',\n",
              " 'control',\n",
              " 'far',\n",
              " 'discussion',\n",
              " 'programming',\n",
              " 'discrete',\n",
              " 'mechanical',\n",
              " 'conception',\n",
              " 'assignment',\n",
              " 'value',\n",
              " 'memory',\n",
              " 'found',\n",
              " 'see',\n",
              " 'functional',\n",
              " '===',\n",
              " 'many',\n",
              " 'natural',\n",
              " 'pseudocode',\n",
              " 'drakon-charts',\n",
              " 'table',\n",
              " 'expression',\n",
              " 'tend',\n",
              " 'complex',\n",
              " 'technical',\n",
              " 'structured',\n",
              " 'express',\n",
              " 'statement',\n",
              " 'intended',\n",
              " 'often',\n",
              " 'document',\n",
              " 'There',\n",
              " 'representation',\n",
              " 'diagram',\n",
              " 'code',\n",
              " 'three',\n",
              " 'level',\n",
              " 'description',\n",
              " 'follows',\n",
              " 'High-level',\n",
              " '…prose',\n",
              " 'implementation',\n",
              " 'need',\n",
              " 'tape',\n",
              " 'head',\n",
              " 'Implementation',\n",
              " 'store',\n",
              " 'Formal',\n",
              " 'Most',\n",
              " 'detailed',\n",
              " 'Algorithm',\n",
              " 'Examples',\n",
              " 'design',\n",
              " 'mathematical',\n",
              " 'dynamic',\n",
              " 'implementing',\n",
              " 'pattern',\n",
              " 'One',\n",
              " 'important',\n",
              " 'resource',\n",
              " 'run-time',\n",
              " 'efficiency',\n",
              " 'big',\n",
              " 'e.g',\n",
              " 'size',\n",
              " 'development',\n",
              " 'Problem',\n",
              " 'Development',\n",
              " 'model',\n",
              " 'correctness',\n",
              " 'testing',\n",
              " 'implemented',\n",
              " 'However',\n",
              " 'network',\n",
              " 'arithmetic',\n",
              " 'looking',\n",
              " 'electrical',\n",
              " 'Computer',\n",
              " 'instance',\n",
              " 'software',\n",
              " 'target',\n",
              " 'even',\n",
              " 'running',\n",
              " 'hardware',\n",
              " 'faster',\n",
              " 'result',\n",
              " 'non-optimal',\n",
              " 'complexity',\n",
              " 'like',\n",
              " 'technology',\n",
              " 'Elegant',\n",
              " 'simplicity',\n",
              " 'elegance',\n",
              " 'appears',\n",
              " 'Knuth',\n",
              " 'Chaitin',\n",
              " 'want',\n",
              " 'length',\n",
              " 'taken',\n",
              " 'etc',\n",
              " \"'elegant\",\n",
              " 'show',\n",
              " 'proof',\n",
              " 'versus',\n",
              " 'multiple',\n",
              " 'true',\n",
              " 'available',\n",
              " 'programmer',\n",
              " 'observes',\n",
              " '...',\n",
              " 'i.e',\n",
              " 'mapping',\n",
              " 'several',\n",
              " 'different',\n",
              " 'goodness',\n",
              " 'speed',\n",
              " 'compactness',\n",
              " 'elegant',\n",
              " 'take',\n",
              " 'le',\n",
              " 'Euclid',\n",
              " 'computor',\n",
              " 'type',\n",
              " 'Melzak',\n",
              " 'Lambek',\n",
              " 'primitive',\n",
              " 'reduced',\n",
              " 'four',\n",
              " 'distinguishable',\n",
              " 'location',\n",
              " 'agent',\n",
              " 'relative',\n",
              " 'describes',\n",
              " 'abacus',\n",
              " 'six',\n",
              " 'depending',\n",
              " 'unless',\n",
              " 'either',\n",
              " 'IF-THEN',\n",
              " 'GOTO',\n",
              " 'unconditional',\n",
              " 'change',\n",
              " 'HALT',\n",
              " 'includes',\n",
              " 'replacement',\n",
              " 'content',\n",
              " 'DECREMENT',\n",
              " 'required',\n",
              " 'exact',\n",
              " 'somewhat',\n",
              " 'constructed',\n",
              " 'zero',\n",
              " 'THEN',\n",
              " 'best',\n",
              " 'immediately',\n",
              " 'paper',\n",
              " 'simulation',\n",
              " 'real',\n",
              " 'execute',\n",
              " 'quadratic',\n",
              " 'know',\n",
              " 'square',\n",
              " 'instead',\n",
              " 'choice',\n",
              " 'point',\n",
              " 'When',\n",
              " 'matter',\n",
              " 'compute',\n",
              " 'remainder',\n",
              " 'modulus',\n",
              " 'rather',\n",
              " 'subtraction',\n",
              " 'worse',\n",
              " 'canonical',\n",
              " 'Church–Turing',\n",
              " 'computed',\n",
              " 'observe',\n",
              " 'GOTOs',\n",
              " 'using',\n",
              " 'Tausworthe',\n",
              " 'SEQUENCE',\n",
              " 'IF-THEN-ELSE',\n",
              " 'additional',\n",
              " 'Its',\n",
              " 'directed',\n",
              " 'rectangle',\n",
              " 'dot',\n",
              " 'made',\n",
              " 'single',\n",
              " 'build',\n",
              " 'shown',\n",
              " 'simplest',\n",
              " 'largest',\n",
              " 'high-level',\n",
              " 'prose',\n",
              " 'remaining',\n",
              " 'larger',\n",
              " 'current',\n",
              " 'consider',\n",
              " 'left',\n",
              " 'closer',\n",
              " 'Elementary',\n",
              " 'Number',\n",
              " 'Theory',\n",
              " 'Elements',\n",
              " 'thus',\n",
              " 'Given',\n",
              " 'measure',\n",
              " 'positive',\n",
              " 'shorter',\n",
              " 'measuring',\n",
              " 'portion',\n",
              " 'succeed',\n",
              " 'satisfy',\n",
              " 'test',\n",
              " 'equal',\n",
              " 'yield',\n",
              " 'original',\n",
              " 'construct',\n",
              " 'While',\n",
              " 'Nicomachus',\n",
              " 'really',\n",
              " '====',\n",
              " 'logical',\n",
              " 'symbolized',\n",
              " 'letter',\n",
              " 'quantity',\n",
              " 'might',\n",
              " '3009',\n",
              " 'version',\n",
              " 'boldface',\n",
              " 'INPUT',\n",
              " 'make',\n",
              " 'Ensure',\n",
              " 'ELSE',\n",
              " 'repeatedly',\n",
              " 'done',\n",
              " 'last',\n",
              " 'previously',\n",
              " 'OUTPUT',\n",
              " 'STOP',\n",
              " 'core',\n",
              " 'thirteen',\n",
              " 'Inelegant',\n",
              " 'back',\n",
              " 'computes',\n",
              " 'minuend',\n",
              " 'subtrahend',\n",
              " 'become',\n",
              " 'Another',\n",
              " 'relatively',\n",
              " 'What',\n",
              " 'happens',\n",
              " 'forever',\n",
              " 'failure',\n",
              " 'total',\n",
              " 'due',\n",
              " 'induction',\n",
              " 'application',\n",
              " 'proposes',\n",
              " 'applicable',\n",
              " 'With',\n",
              " 'compared',\n",
              " 'analysis',\n",
              " 'whereas',\n",
              " 'needed',\n",
              " 'improved',\n",
              " 'question',\n",
              " 'proved',\n",
              " 'generalized',\n",
              " 'exhaustive',\n",
              " 'search',\n",
              " 'error',\n",
              " 'provides',\n",
              " 'together',\n",
              " 'reduces',\n",
              " 'moving',\n",
              " 'call',\n",
              " 'Algorithmic',\n",
              " 'frequently',\n",
              " 'particular',\n",
              " 'developed',\n",
              " 'answer',\n",
              " 'sorting',\n",
              " 'said',\n",
              " 'counted',\n",
              " 'binary',\n",
              " 'cost',\n",
              " 'sorted',\n",
              " 'array',\n",
              " 'study',\n",
              " 'discipline',\n",
              " 'property',\n",
              " 'algorithmic',\n",
              " 'significant',\n",
              " 'designed',\n",
              " 'Empirical',\n",
              " 'potential',\n",
              " 'improvement',\n",
              " 'optimization',\n",
              " 'manner',\n",
              " 'field',\n",
              " 'image',\n",
              " 'decrease',\n",
              " 'medical',\n",
              " 'special',\n",
              " 'digital',\n",
              " 'power',\n",
              " 'classify',\n",
              " 'merit',\n",
              " 'reference',\n",
              " 'condition',\n",
              " 'Iterative',\n",
              " 'Some',\n",
              " 'well',\n",
              " 'Every',\n",
              " 'equivalent',\n",
              " 'Logical',\n",
              " 'deduction',\n",
              " 'component',\n",
              " 'applied',\n",
              " 'paradigm',\n",
              " 'pure',\n",
              " 'fixed',\n",
              " 'approach',\n",
              " 'parallel',\n",
              " 'distributed',\n",
              " 'serial',\n",
              " 'Parallel',\n",
              " 'processor',\n",
              " 'divide',\n",
              " 'subproblems',\n",
              " 'consumption',\n",
              " 'communication',\n",
              " 'overhead',\n",
              " 'expensive',\n",
              " 'inherently',\n",
              " 'Deterministic',\n",
              " 'non-deterministic',\n",
              " 'accurate',\n",
              " 'approximate',\n",
              " 'approximation',\n",
              " 'item',\n",
              " 'goal',\n",
              " 'get',\n",
              " 'weight',\n",
              " 'carried',\n",
              " 'Quantum',\n",
              " 'run',\n",
              " 'quantum',\n",
              " 'category',\n",
              " 'Brute-force',\n",
              " 'Divide',\n",
              " 'conquer',\n",
              " 'merge',\n",
              " 'segment',\n",
              " 'identical',\n",
              " 'subproblem',\n",
              " 'enumeration',\n",
              " 'graph',\n",
              " 'bound',\n",
              " 'impractical',\n",
              " 'fastest',\n",
              " 'polynomial',\n",
              " 'open',\n",
              " 'return',\n",
              " 'correct',\n",
              " 'E.g',\n",
              " 'involves',\n",
              " 'built',\n",
              " 'determined',\n",
              " 'lead',\n",
              " 'full',\n",
              " 'Linear',\n",
              " 'linear',\n",
              " 'constraint',\n",
              " 'popular',\n",
              " 'solved',\n",
              " 'unknown',\n",
              " 'classified',\n",
              " 'restriction',\n",
              " 'Dynamic',\n",
              " 'already',\n",
              " 'shortest',\n",
              " 'path',\n",
              " 'vertex',\n",
              " 'memoization',\n",
              " 'difference',\n",
              " 'independent',\n",
              " 'overlap',\n",
              " 'recursion',\n",
              " 'hence',\n",
              " 'exponential',\n",
              " 'greedy',\n",
              " 'similar',\n",
              " 'improve',\n",
              " 'making',\n",
              " 'local',\n",
              " 'optimum',\n",
              " 'tree',\n",
              " 'close',\n",
              " 'principle',\n",
              " 'tabu',\n",
              " 'annealing',\n",
              " 'Related',\n",
              " 'studied',\n",
              " 'numerical',\n",
              " 'cryptography',\n",
              " 'compression',\n",
              " 'completely',\n",
              " 'invented',\n",
              " 'continuous',\n",
              " 'operating',\n",
              " 'issue',\n",
              " 'patentable',\n",
              " 'highly',\n",
              " 'patent',\n",
              " 'especially',\n",
              " 'export',\n",
              " 'History',\n",
              " 'earliest',\n",
              " 'clay',\n",
              " 'tablet',\n",
              " 'circa',\n",
              " 'mark',\n",
              " 'Post–Turing',\n",
              " 'algebra',\n",
              " 'Al-jabr',\n",
              " 'refer',\n",
              " 'Leibniz',\n",
              " 'manipulating',\n",
              " 'Cryptographic',\n",
              " 'contrivance',\n",
              " 'clock',\n",
              " 'invention',\n",
              " 'key',\n",
              " 'led',\n",
              " 'beginning',\n",
              " 'engine',\n",
              " 'analytical',\n",
              " 'Babbage',\n",
              " 'Lovelace',\n",
              " 'mid-19th',\n",
              " 'history',\n",
              " '1870',\n",
              " 'Jevons',\n",
              " 'presented',\n",
              " 'however',\n",
              " 'came',\n",
              " 'effort',\n",
              " 'interest',\n",
              " 'importance',\n",
              " 'characterization',\n",
              " 'Prof.',\n",
              " 'suppose',\n",
              " 'loom',\n",
              " 'Hollerith',\n",
              " 'punch',\n",
              " 'telegraphy',\n",
              " 'electromechanical',\n",
              " 'relay',\n",
              " 'Bell',\n",
              " 'precursor',\n",
              " 'telephone',\n",
              " 'leading',\n",
              " 'ticker',\n",
              " 'George',\n",
              " 'Stibitz',\n",
              " '1937',\n",
              " 'adding',\n",
              " 'observed',\n",
              " 'calculator',\n",
              " 'Mathematics',\n",
              " 'rapid',\n",
              " 'succession',\n",
              " 'Frege',\n",
              " '1879',\n",
              " 'Peano',\n",
              " 'manipulated',\n",
              " 'symbolic',\n",
              " 'definite',\n",
              " 'Russell',\n",
              " 'Principia',\n",
              " 'Mathematica',\n",
              " 'paradox',\n",
              " 'appeared',\n",
              " 'Gödel',\n",
              " '1931',\n",
              " 'Stephen',\n",
              " 'Kleene',\n",
              " 'J.B.',\n",
              " 'Rosser',\n",
              " 'Herbrand',\n",
              " 'unsolvable',\n",
              " 'worker',\n",
              " 'Barkley',\n",
              " 'Thesis',\n",
              " 'year',\n",
              " 'box',\n",
              " 'say',\n",
              " 'stroke',\n",
              " 'marked',\n",
              " 'direction',\n",
              " 'See',\n",
              " 'typewriter',\n",
              " 'mind',\n",
              " 'Computing',\n",
              " 'divided',\n",
              " 'shall',\n",
              " 'moment',\n",
              " 'imagine',\n",
              " 'easy',\n",
              " 'therefore',\n",
              " 'Changes',\n",
              " 'calculable',\n",
              " 'purely',\n",
              " 'intuitive',\n",
              " 'identification',\n",
              " 'footnote',\n",
              " 'reading',\n",
              " 'Stony',\n",
              " 'Brook',\n",
              " 'University',\n",
              " 'Stanford']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCwtLSB6rcu5",
        "outputId": "b97b031d-c271-4146-ed97-30abbdee9e88"
      },
      "source": [
        "wikimodel.wv.most_similar(positive = [\"finite\", \"instruction\"], topn = 3)\n",
        "print(wikimodel.wv.similarity(\"solve\", \"instruction\"))\n",
        "print(wikimodel.wv.similarity(\"class\", \"goal\"))\n",
        "print(wikimodel.wv.similarity(\"data\", \"system\"))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.24535204\n",
            "0.09708051\n",
            "0.12937728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS5659kMx_d4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}